---
title: "Bayesian Staggered DID"
format: html
editor: visual
---

```{r}
# Load the necessary libraries
#install.packages("brms")
library("brms")
library("tidyverse") # For data manipulation
library("did")
library("panelView")
library("dplyr")
library("tidyverse")
library("cobalt")
library("furrr")
library("future")
#install.packages("future")
```

```{r}
# Set seed
set.seed(12345)

effect_scale <- 1

# Data generating process with 6 time periods after adoption and 1000 observations
dgp <- reset.sim(
                time.periods <- 5,
                n = 1000,
                ipw = TRUE,
                reg = TRUE
                )
dgp$te <- 0

# Add dynamic effects
dgp$te.e <- 1:time.periods * effect_scale

# Drop observations where the implementation of the EBP was on period 1. According to Callaway & Sant'Anna, these observations do not help in estimating the ATT(g, t). 
data1 <- build_sim_dataset(dgp)

data1$long <- 0

# Generate the indicator for adoption across time. If the observation adopts the EBP, they will be coded as 1 at the time of adoption and 1 for all periods after. 
data1$long[data1$period < data1$G] = 0
data1$long[data1$period >= data1$G] = 1

# How many observations remained after dropping the observations that had adopted the EBP at time period = 1
nrow(data1)
```





```{r}
# --- Stage 1: Propensity Score Estimation ---

# Generate the realistic, complex dataset
set.seed(12345)
dgp_realistic <- reset.sim(
    time.periods = 6,
    n = 500,
    ipw = TRUE,  # <-- Realistic: Selection bias based on X
    reg = TRUE   # <-- Realistic: Outcome Y depends on X
)
dgp_realistic$te <- 0
dgp_realistic$te.e <- 1:time.periods * effect_scale
data_realistic <- build_sim_dataset(dgp_realistic)

# We need a factor version of the cohort variable `G` for the model
# We'll also combine never-treated (G=0) and not-yet-treated into a single "control" category
# for the purpose of this selection model, which simplifies things.
# For modeling, we need one observation per unit `id`.
propensity_data <- data_realistic %>%
  distinct(id, G, X) %>%
  mutate(G_factor = factor(G))

# Fit a Bayesian multinomial model to estimate P(G | X)
# This model learns how X predicts which cohort a unit will be in.
propensity_model <- brm(
  formula = G_factor ~ X,
  data = propensity_data,
  family = categorical(), # This specifies a multinomial model
  cores = 4,
  seed = 12345,
  silent = 2,
  file = "propensity_model" # Cache the model
)

# Predict the probability for each unit belonging to its ACTUAL observed cohort
# This gives us the propensity scores.
prop_scores <- fitted(propensity_model, newdata = propensity_data, summary = FALSE)
```


```{r}
# `prop_scores` is an array: [draws, cases, categories]
# We need to extract the probability corresponding to the actual cohort for each unit
# This is a bit complex, but this code works:
propensity_data$prop_score <- map_dbl(1:nrow(propensity_data), function(i) {
  # For unit i, find its actual cohort level
  actual_cohort_level <- which(levels(propensity_data$G_factor) == propensity_data$G_factor[i])
  # Get the mean probability across all posterior draws for that unit and that cohort
  mean(prop_scores[, i, actual_cohort_level])
})
```


```{r}
# Calculate the IPW weights. The simplest form is 1 / P(treatment received)
propensity_data <- propensity_data %>%
  mutate(ipw_weight = 1 / prop_score)

# Join the weights back to the main longitudinal dataset
data_weighted <- data_realistic %>%
  left_join(propensity_data %>% select(id, ipw_weight), by = "id")
```

```{r}
# --- Trim the Weights ---

# Calculate the 99th percentile threshold (or 98th, or 99.5th)
weight_cap <- quantile(data_weighted$ipw_weight, 0.99)

cat(paste("\n--- Capping weights at the 99th percentile:", round(weight_cap, 2), "---\n"))

# Create a new column with the trimmed weights
data_weighted <- data_weighted %>%
  mutate(ipw_weight_trimmed = ifelse(ipw_weight > weight_cap, weight_cap, ipw_weight))
```


```{r}
# --- Investigate the IPW Weights ---

cat("\n--- Summary of Original IPW Weights ---\n")
print(summary(data_weighted$ipw_weight))

# It's also very helpful to see a histogram
# You are looking for a long right tail of extreme values
hist(data_weighted$ipw_weight, breaks = 100, main = "Histogram of Original IPW Weights")

# For very skewed data, looking at the log might be more informative
hist(log(data_weighted$ipw_weight), breaks = 100, main = "Histogram of Log(IPW Weights)")
```



```{r}

# Assess the balance on the covariate X across the treatment cohorts G
# We compare the unweighted data with the IPW-weighted data.
balance_assessment <- bal.tab(
  G ~ X,                               # Formula: treatment variable ~ covariates
  data = data_weighted,                # The dataset to use
  weights = "ipw_weight",              # The column containing the IPW weights
  method = "weighting",                # Specify that we are using weights
  un = TRUE,                           # Display balance for the unweighted data as well
  estimand = "ATE"                     # We are estimating the Average Treatment Effect
)

# Print the balance table
print(balance_assessment)

# Generate the Love Plot
love.plot(
  balance_assessment,
  threshold = 0.1,                     # Add a line for the 0.1 SMD threshold
  title = "Covariate Balance Before and After IPW",
  stars = "raw"
)


cat("\n--- Stage 1 Complete: Propensity scores and weights calculated. ---\n")
```




```{r}
# --- Stage 2: Weighted Outcome Model ---

# Set up a parallel processing plan. This will use 4 cores.
# The plan is "sticky", so you only need to run this once per session.
plan(multisession, workers = 4)

cohorts_to_loop <- sort(unique(data_weighted$G[data_weighted$G > 1]))

# Replace the for() loop with future_map()
# `future_map_dfr` will run the code for each cohort in parallel
# and combine the resulting data frames at the end.
all_cohort_results_df <- future_map_dfr(cohorts_to_loop, .f = function(g) {

  cat(paste("\n--- Processing Cohort G =", g, "(Corrected Weighted Model) ---\n"))

  # --- Your existing logic from inside the loop goes here ---

  data_subset <- data_weighted %>%
    filter(G == g | G == 0 | G > g) %>%
    mutate(
      treat = factor(ifelse(G == g, 1, 0)),
      period_fct = factor(period)
    )

  brm_weighted_fit <- brm(
    formula = Y | weights(ipw_weight) ~ (1|id) + (1|period) + treat:period_fct, # <-- WEIGHTS ARE BACK IN
    data = data_subset,
    family = gaussian(),
    prior = c(prior(normal(0, 1), class = "b")),  # <-- KEEP THE STRONG PRIOR
    control = list(adapt_delta = 0.99),
    iter = 2000,                                 # <-- KEEP THE HIGHER ITERATIONS
    cores = 1,
    seed = 12345,
    silent = 2
)

  cohort_draws <- posterior::as_draws_df(brm_weighted_fit) %>%
    select(.draw, starts_with("b_treat1:period_fct")) %>%
    pivot_longer(cols = -".draw", names_to = "term", values_to = "att_draw") %>%
    mutate(
      period = as.numeric(str_extract(term, "[0-9]+$")),
      event_time = period - g,
      cohort = g
    ) %>%
    filter(event_time >= 0)

  # Return the results for this cohort
  return(cohort_draws)

}, .options = furrr_options(seed = TRUE)) # Ensures reproducibility

cat("\n--- All Cohorts Processed in Parallel ---\n")

```


```{r}
# --- Stage 3: Aggregate and Plot Final Results ---

# The previous `future_map_dfr` call has already created a single,
# combined data frame called `all_cohort_results_df`.
# We no longer need the `bind_rows()` step.

cat("\n--- All cohorts processed. Aggregating final results... ---\n")

# The pipe now starts directly with the output from future_map_dfr
dynamic_effects_summary <- all_cohort_results_df %>%
  group_by(event_time) %>%
  summarise(
    Estimate = mean(att_draw),
    Q2.5 = quantile(att_draw, 0.025),
    Q97.5 = quantile(att_draw, 0.975),
    .groups = "drop"
  )

# Add the pre-treatment period at t-1 for plotting
# (This part of the logic remains the same)
dynamic_effects_plot_data <- bind_rows(
  tibble(event_time = -1, Estimate = 0, Q2.5 = 0, Q97.5 = 0),
  dynamic_effects_summary
) %>% arrange(event_time)


# The plotting code itself does not need to change,
# it just uses the final summarized data frame.
print(
  ggplot(dynamic_effects_plot_data, aes(x = event_time, y = Estimate)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    geom_point(size = 3, color = "darkblue") +
    geom_errorbar(aes(ymin = Q2.5, ymax = Q97.5), width = 0.2, color = "darkblue") +
    labs(
      title = "Dynamic Treatment Effects with IPW",
      subtitle = "Adjusted for selection bias using a Bayesian DiD model with IPW",
      x = "Time Relative to Treatment",
      y = "Average Treatment Effect on the Treated (ATT)"
    ) +
    theme_minimal(base_size = 14)
)
```


